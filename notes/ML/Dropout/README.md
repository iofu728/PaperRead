# Dropout

1. [**Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models**](https://github.com/iofu728/PaperRead/blob/master/paper/ML/Dropout/Mixout.pdf) [ICLR 2020] _Cheolhyoung Lee, Kyunghyun Cho, Wanmo Kang_.
   - finetune on large-scale dataset to reduce overfiting.
   - Origin + Dropout
   - proof the random mixture function have one lower bound.
